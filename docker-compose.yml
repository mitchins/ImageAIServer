version: '3.8'

services:
  imageaiserver:
    build: .
    ports:
      - "8000:8000"
    environment:
      # Production optimizations
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      
      # HuggingFace cache directory (can be overridden)
      - HF_HOME=/app/.cache/huggingface
      
      # Optional: Set specific model presets
      # - USE_MOCK_ONNX=false
      
    volumes:
      # Persist model cache across container restarts
      - model_cache:/app/.cache/huggingface
      
      # Optional: Mount local model cache if you have models pre-downloaded
      # - ~/.cache/huggingface:/app/.cache/huggingface
      
    restart: unless-stopped
    
    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Optional: GPU-enabled version (uncomment to use)
  # imageaiserver-gpu:
  #   build: .
  #   runtime: nvidia
  #   environment:
  #     - NVIDIA_VISIBLE_DEVICES=all
  #     - PYTHONUNBUFFERED=1
  #     - PYTHONDONTWRITEBYTECODE=1
  #   ports:
  #     - "8000:8000"
  #   volumes:
  #     - model_cache:/app/.cache/huggingface

volumes:
  model_cache:
    driver: local